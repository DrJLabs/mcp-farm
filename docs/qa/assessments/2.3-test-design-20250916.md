# Test Design: Story 2.3 — Expand Unit & Integration Coverage

Date: 2025-09-16
Designer: Quinn (Test Architect)

## Test Strategy Overview
- Total test scenarios: 10
- Unit tests: 4 (40%)
- Integration tests: 6 (60%)
- E2E tests: 0 (integration covers streaming)
- Priority distribution: P0: 6, P1: 3, P2: 1

Goal is to raise confidence around sample MCP functionality and streaming. Unit coverage ensures deterministic behavior; integration tests validate runtime wiring.

## Test Scenarios by Acceptance Criteria

### AC1: Unit coverage for `search`

| ID           | Level | Priority | Test                                                                 | Justification |
|--------------|-------|----------|---------------------------------------------------------------------|---------------|
| 2.3-UNIT-001 | Unit  | P0       | `search` returns expected results for keyword hit                   | Guard core behavior |
| 2.3-UNIT-002 | Unit  | P0       | `search` returns empty list when no matches                         | Negative path |

### AC1/AC2: Unit coverage for `fetch`

| ID           | Level | Priority | Test                                                                 | Justification |
|--------------|-------|----------|---------------------------------------------------------------------|---------------|
| 2.3-UNIT-003 | Unit  | P0       | `fetch` returns structured result for known ID                      | Contract |
| 2.3-UNIT-004 | Unit  | P0       | `fetch` raises ValueError for unknown ID                            | Error handling |

### AC2: Auth edge cases

| ID           | Level | Priority | Test                                                                 | Justification |
|--------------|-------|----------|---------------------------------------------------------------------|---------------|
| 2.3-INT-001  | Int   | P0       | Auth-enabled server: JWT fallback path exercised (primary + alt audience) | Validate env logic |
| 2.3-INT-002  | Int   | P1       | Auth-disabled server: ensure no auth provider configured            | Prevent regressions |

### AC3: Streaming smoke via pytest

| ID           | Level | Priority | Test                                                                 | Justification |
|--------------|-------|----------|---------------------------------------------------------------------|---------------|
| 2.3-INT-003  | Int   | P0       | Streaming test receives ≥10 chunks or completes within timeout      | Ensures streaming works |
| 2.3-INT-004  | Int   | P0       | Streaming test enforces timeout and fails fast on hang              | Mitigates PERF-301 |

### AC4: Coverage enforcement

| ID           | Level | Priority | Test                                                                 | Justification |
|--------------|-------|----------|---------------------------------------------------------------------|---------------|
| 2.3-INT-005  | Int   | P0       | `uv run pytest --cov --cov-fail-under=80` returns 0                 | Enforces threshold |
| 2.3-INT-006  | Int   | P1       | Coverage artifacts generated at `tests/coverage/` (xml + HTML)      | Evidence |

### Additional Safeguards

| ID           | Level | Priority | Test                                                                 | Justification |
|--------------|-------|----------|---------------------------------------------------------------------|---------------|
| 2.3-INT-007  | Int   | P2       | `pytest --markers` lists integration marker description             | Documentation |

## Risk Coverage
- PERF-301 mitigated via streaming timeout tests.
- OPS-301 covered by coverage enforcement scenario.
- SEC-302 addressed via negative tests.

## Recommended Execution Order
1. Unit tests (2.3-UNIT-001..004).
2. Auth integration tests (2.3-INT-001, 2.3-INT-002).
3. Streaming integration (2.3-INT-003, 2.3-INT-004).
4. Coverage command (2.3-INT-005) and artifact check (2.3-INT-006).
5. Marker listing (2.3-INT-007).

## Notes for Implementers
- Use fixtures for sample records to avoid global state changes.
- When wrapping streaming script, prefer asynchronous client with `asyncio.wait_for` for timeout.
- Add `pytest.ini` marker description: `integration: long-running or external resource tests`.

## Gate Block (for future gate file)
```yaml
test_design:
  scenarios_total: 10
  by_level:
    unit: 4
    integration: 6
    e2e: 0
  by_priority:
    p0: 6
    p1: 3
    p2: 1
  coverage_gaps:
    - Consider follow-up for performance benchmarks under load once streaming stabilized.
```

## Story Hook
Test design matrix: docs/qa/assessments/2.3-test-design-20250916.md
